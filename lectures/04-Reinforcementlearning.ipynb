{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a december\n",
    "\n",
    "# Reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feedback loopen är inte mellan testfall utan efter vad som händer i verkligheten.\n",
    "- Agenter: Algoritmer\n",
    "- Q-Learning\n",
    "    - Googles uppfinning\n",
    "    - Den som började klara schack och Go\n",
    "- Det finns inga labelar, det finns inget sätt att göra unsuperviced.\n",
    "- Morot och piska, belöna och straffa beteenden\n",
    "- Vad vi behöver:\n",
    "    - En/flera agenter\n",
    "    - En miljö\n",
    "    - State\n",
    "    - Möjliga val\n",
    "    - Belöning\n",
    "    - Policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q-learning\n",
    "    - Kopiera ett nätverk som fungerar på nutid\n",
    "    - Använd det för att förutsätta framtiden\n",
    "    - Loopa mellan varandra, de ändrar lite på varandra hela tiden\n",
    "    - Q(state,action)<-(1-a)(Q(state,action)+a(reward+y(max(Q(next_state, next_action)))))\n",
    "- Initialisering\n",
    "- Välja en åtgärd - Utforskning vs Utnyttjande\n",
    "- Uppdatera Q-tabellen\n",
    "- Upprepa processen\n",
    "- Konvergens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Deep Q-learning\n",
    "- Istället för ett Qtabel så använder vi ett NN för att hantera situationer/states\n",
    "- Replay\n",
    "    - Vi tränar på ett minne om vad som hänt.\n",
    "- Istället för Epocher har vi Episoder\n",
    "    - Episod = En \"körning\", ett spel tills man dör etc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
