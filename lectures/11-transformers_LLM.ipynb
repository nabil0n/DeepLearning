{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18e December\n",
    "\n",
    "# Transformers - LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encoder / Decoder -> LLMer är decoder\n",
    "- tidigare har vi gjort\n",
    "    - classification (sigmoid): enkel regression ()\n",
    "    - multiclass (softmax): multipel regression ()\n",
    "- sequence to sequence learning\n",
    "    - är istället från samma mängd av noder till samma mängd av noder typ (?)\n",
    "- Attention, aka \"neural attention\"\n",
    "    - Conv2d\n",
    "    - **MaxPooling** <-- en sorts attention ( selects ONE feature out of many)\n",
    "    - **TF-IDF** <-- en sorts attention (viktar ord according to document freq)\n",
    "    - Attention är alltså bara **a set of weights**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention: Outputs = sum(values * pairwise(query, keys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Staplade bilder exempel\n",
    "    - Query: \"dogs on the beach\"\n",
    "    - bara attention:\n",
    "        - Varje bild har en key: \"cat\", \"dog\", \"sun\", \"party\"...\n",
    "        - matcha keys till query med någon form av \"importance\", alltså en weight.\n",
    "        - values = the matching images with scores\n",
    "### Self-attention: Outputs = sum(**input** * pairwise(**input, input**))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- samma exempel:\n",
    "    - nu kollar vi alltså på varje ord i meningen till varandra.\n",
    "        - \"dog\" -> \"on\", \"the\", \"beach\"\n",
    "        - \"on\" -> \"dog\", \"the\", \"beach\"\n",
    "        - osv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../data/encoderdecoder.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "- Nyaste LLMer är \"decoder only\n",
    "- Problem: **L**LM -> Large'\n",
    "- Behöver absurt mycket data\n",
    "    - kvalitet på mycket data är svårkontrollerad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Den neurala arkitekturen är viktig\n",
    "    - oftan Dense layers som \"standard\"\n",
    "    - men alltmer vanligt är \"instruction following\" och \"mixture of expert\" modeller.\n",
    "- instruction following:\n",
    "    - extra bit in query; a so-called system-prompt\n",
    "    - should follow prompt in every call\n",
    "    - de flesta populära modeller använder detta (llama, gemma, mistral, etc) har separerade instruction models\n",
    "- mixture of experts:\n",
    "    - Exempelmodell: Mixtral\n",
    "        - en mix-modell av mistral\n",
    "        - 8 x 2 BT, alltså 8 modeller med 2 miljarder params vardera\n",
    "            - tex: en modell för code, en för popkultur osv\n",
    "        - Man kör den parallellt och sedan gör någon form av pooling/**attention** i slutet\n",
    "    - mindre minnes användning, men beter sig som en mycket större modell\n",
    "    - Behöver istället mer compute\n",
    "    - modellformen är mest för prestandaoptimering, men har visat sig vara väldigt bra i vissa fall\n",
    "        - Lättare att se vilka submodeller som faktiskt är bra och dåliga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
